{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"extraction/data_censored.csv\"\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "try:\n",
    "    data_censored = pd.read_csv(file_path)\n",
    "    print(\"Data loaded successfully!\")\n",
    "    print(data_censored.head())  # Display the first few rows\n",
    "except FileNotFoundError:\n",
    "    print(f\"File not found at {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directories for saving results\n",
    "trial_pp_dir = os.path.join(os.getcwd(), \"trial_pp\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "\n",
    "trial_itt_dir = os.path.join(os.getcwd(), \"trial_itt\")\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to structure the trial data\n",
    "def set_data(trial_name, data, id_col, period_col, treatment_col, outcome_col, eligible_col):\n",
    "    \"\"\"Prepare a dictionary to structure trial data.\"\"\"\n",
    "    return {\n",
    "        \"trial_name\": trial_name,\n",
    "        \"data\": data,\n",
    "        \"id\": data[id_col],\n",
    "        \"period\": data[period_col],\n",
    "        \"treatment\": data[treatment_col],\n",
    "        \"outcome\": data[outcome_col],\n",
    "        \"eligible\": data[eligible_col],\n",
    "    }\n",
    "\n",
    "# Per-Protocol (PP)\n",
    "trial_pp = set_data(\n",
    "    trial_name=\"PP\",\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    ")\n",
    "\n",
    "# Intention-To-Treat (ITT)\n",
    "trial_itt = set_data(\n",
    "    trial_name=\"ITT\",\n",
    "    data=data_censored,\n",
    "    id_col=\"id\",\n",
    "    period_col=\"period\",\n",
    "    treatment_col=\"treatment\",\n",
    "    outcome_col=\"outcome\",\n",
    "    eligible_col=\"eligible\",\n",
    ")\n",
    "\n",
    "# Print the structured ITT trial data\n",
    "print(trial_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define directory for saving models\n",
    "trial_pp_dir = os.path.join(os.getcwd(), \"trial_pp\")\n",
    "os.makedirs(trial_pp_dir, exist_ok=True)\n",
    "\n",
    "# Separate data for treatment = 1 and treatment = 0 in the previous period\n",
    "data_treated = data_censored[data_censored['treatment'].shift(1) == 1]\n",
    "data_untreated = data_censored[data_censored['treatment'].shift(1) == 0]\n",
    "\n",
    "# Define function to fit logistic regression models\n",
    "def fit_logit_model(data, formula, save_path):\n",
    "    \"\"\"Fits a logistic regression model and saves it.\"\"\"\n",
    "    y = data['treatment']  # Dependent variable (treatment in current period)\n",
    "    X = data[formula]  # Independent variables\n",
    "    X = sm.add_constant(X)  # Add intercept term\n",
    "    \n",
    "    model = sm.Logit(y, X).fit()\n",
    "    \n",
    "    # Save model summary\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(model.summary().as_text())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit numerator model (only age as predictor)\n",
    "numerator_model = fit_logit_model(data_censored, [\"age\"], os.path.join(trial_pp_dir, \"switch_numerator_model.txt\"))\n",
    "\n",
    "# Fit denominator model (age + x1 + x3 as predictors)\n",
    "denominator_model = fit_logit_model(data_censored, [\"age\", \"x1\", \"x3\"], os.path.join(trial_pp_dir, \"switch_denominator_model.txt\"))\n",
    "\n",
    "# Compute stabilized weights\n",
    "data_censored[\"numerator_prob\"] = numerator_model.predict(sm.add_constant(data_censored[[\"age\"]]))\n",
    "data_censored[\"denominator_prob\"] = denominator_model.predict(sm.add_constant(data_censored[[\"age\", \"x1\", \"x3\"]]))\n",
    "data_censored[\"switch_weight\"] = data_censored[\"numerator_prob\"] / data_censored[\"denominator_prob\"]\n",
    "\n",
    "# Print first few switch weights\n",
    "print(data_censored[[\"id\", \"switch_weight\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define directories for saving models\n",
    "\n",
    "trial_itt_dir = os.path.join(os.getcwd(), \"trial_itt\")\n",
    "os.makedirs(trial_itt_dir, exist_ok=True)\n",
    "\n",
    "# Define function to fit logistic regression models\n",
    "def fit_logit_model(data, formula_vars, dependent_var, save_path):\n",
    "    \"\"\"Fits a logistic regression model and saves it.\"\"\"\n",
    "    y = data[dependent_var]  # Dependent variable (censoring event)\n",
    "    X = data[formula_vars]  # Independent variables\n",
    "    X = sm.add_constant(X)  # Add intercept term\n",
    "    \n",
    "    model = sm.Logit(y, X).fit()\n",
    "    \n",
    "    # Save model summary\n",
    "    with open(save_path, \"w\") as f:\n",
    "        f.write(model.summary().as_text())\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit numerator model: 1 - censored ~ x2\n",
    "numerator_model_pp = fit_logit_model(\n",
    "    data_censored, \n",
    "    [\"x2\"], \n",
    "    \"censored\", \n",
    "    os.path.join(trial_pp_dir, \"censor_numerator_model.txt\")\n",
    ")\n",
    "\n",
    "# Fit denominator model: 1 - censored ~ x2 + x1\n",
    "denominator_model_pp = fit_logit_model(\n",
    "    data_censored, \n",
    "    [\"x2\", \"x1\"], \n",
    "    \"censored\", \n",
    "    os.path.join(trial_pp_dir, \"censor_denominator_model.txt\")\n",
    ")\n",
    "\n",
    "# Compute stabilized censoring weights\n",
    "data_censored[\"censor_numerator_prob\"] = numerator_model_pp.predict(sm.add_constant(data_censored[[\"x2\"]]))\n",
    "data_censored[\"censor_denominator_prob\"] = denominator_model_pp.predict(sm.add_constant(data_censored[[\"x2\", \"x1\"]]))\n",
    "data_censored[\"censor_weight\"] = data_censored[\"censor_numerator_prob\"] / data_censored[\"censor_denominator_prob\"]\n",
    "\n",
    "# Print first few censoring weights\n",
    "print(data_censored[[\"id\", \"censor_weight\"]].head())\n",
    "\n",
    "# Fit numerator model: 1 - censored ~ x2 + assigned_treatment\n",
    "numerator_model_itt = fit_logit_model(\n",
    "    data_censored, \n",
    "    [\"x2\", \"eligible\"], \n",
    "    \"censored\", \n",
    "    os.path.join(trial_itt_dir, \"censor_numerator_model.txt\")\n",
    ")\n",
    "\n",
    "# Fit denominator model: 1 - censored ~ x2 + x1 + assigned_treatment\n",
    "denominator_model_itt = fit_logit_model(\n",
    "    data_censored, \n",
    "    [\"x2\", \"x1\", \"eligible\"],  \n",
    "    \"censored\", \n",
    "    os.path.join(trial_itt_dir, \"censor_denominator_model.txt\")\n",
    ")\n",
    "\n",
    "# Compute weights for ITT\n",
    "data_censored[\"censor_numerator_prob_itt\"] = numerator_model_itt.predict(sm.add_constant(data_censored[[\"x2\", \"eligible\"]]))\n",
    "data_censored[\"censor_denominator_prob_itt\"] = denominator_model_itt.predict(sm.add_constant(data_censored[[\"x2\", \"x1\", \"eligible\"]]))\n",
    "data_censored[\"censor_weight_itt\"] = data_censored[\"censor_numerator_prob_itt\"] / data_censored[\"censor_denominator_prob_itt\"]\n",
    "\n",
    "# Print ITT censoring weights\n",
    "print(data_censored[[\"id\", \"censor_weight_itt\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit censoring model (numerator)\n",
    "X_n = sm.add_constant(data_censored[['x2']])  # Predictor variables\n",
    "y_n = 1 - data_censored['censored']           # Outcome variable (not censored)\n",
    "censor_model_n = sm.Logit(y_n, X_n).fit()\n",
    "print(censor_model_n.summary())\n",
    "\n",
    "# Fit censoring model (denominator)\n",
    "X_d = sm.add_constant(data_censored[['x2', 'x1']])  \n",
    "y_d = 1 - data_censored['censored']  \n",
    "censor_model_d = sm.Logit(y_d, X_d).fit()\n",
    "print(censor_model_d.summary())\n",
    "\n",
    "# Fit treatment switching model (numerator)\n",
    "X_tn = sm.add_constant(data_censored[['age']])  \n",
    "y_tn = data_censored['treatment']  \n",
    "switch_model_n = sm.Logit(y_tn, X_tn).fit()\n",
    "print(switch_model_n.summary())\n",
    "\n",
    "# Fit treatment switching model (denominator)\n",
    "X_td = sm.add_constant(data_censored[['age', 'x1', 'x3']])  \n",
    "y_td = data_censored['treatment']  \n",
    "switch_model_d = sm.Logit(y_td, X_td).fit()\n",
    "print(switch_model_d.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit treatment switching model (numerator)\n",
    "X_tn = sm.add_constant(data_censored[['age']])  \n",
    "y_tn = data_censored['treatment']  \n",
    "switch_model_n = sm.Logit(y_tn, X_tn).fit()\n",
    "print(switch_model_n.summary())\n",
    "\n",
    "# Fit treatment switching model (denominator)\n",
    "X_td = sm.add_constant(data_censored[['age', 'x1', 'x3']])  \n",
    "y_td = data_censored['treatment']  \n",
    "switch_model_d = sm.Logit(y_td, X_td).fit()\n",
    "print(switch_model_d.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictors\n",
    "X = sm.add_constant(data_censored[['x2']])  # Adjusting for x2\n",
    "y = data_censored['outcome']  \n",
    "\n",
    "# Fit logistic regression model\n",
    "outcome_model = sm.Logit(y, X).fit()\n",
    "print(outcome_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute final stabilized weights\n",
    "data_censored[\"final_weight_pp\"] = data_censored[\"switch_weight\"] * data_censored[\"censor_weight\"]\n",
    "data_censored[\"final_weight_itt\"] = data_censored[\"switch_weight\"] * data_censored[\"censor_weight_itt\"]\n",
    "\n",
    "# Print first few rows to compare\n",
    "print(data_censored[[\"id\", \"final_weight_pp\", \"final_weight_itt\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_trials(data, max_followup=10, trial_type=\"PP\"):\n",
    "    expanded_rows = []\n",
    "    \n",
    "    # Select weight column based on trial type\n",
    "    if trial_type == \"PP\":\n",
    "        weight_col = \"final_weight_pp\"\n",
    "    elif trial_type == \"ITT\":\n",
    "        weight_col = \"final_weight_itt\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid trial type. Choose 'PP' or 'ITT'.\")\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        for t in range(max_followup):  \n",
    "            expanded_rows.append({\n",
    "                'id': row['id'],\n",
    "                'trial_period': t,\n",
    "                'followup_time': t,\n",
    "                'outcome': row['outcome'],  \n",
    "                'weight': row[weight_col],  # Use correct weight column\n",
    "                'treatment': row['treatment'],\n",
    "                'x2': row['x2'],\n",
    "                'age': row['age'],\n",
    "                'assigned_treatment': row['treatment']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Expand PP trial\n",
    "expanded_data_pp = expand_trials(data_censored, trial_type=\"PP\")\n",
    "\n",
    "# Expand ITT trial\n",
    "expanded_data_itt = expand_trials(data_censored, trial_type=\"ITT\")\n",
    "\n",
    "# Check output\n",
    "print(expanded_data_pp.head())\n",
    "print(expanded_data_itt.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_censored.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expanded_data(data, seed=1234, p_control=0.5):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # If p_control < 1, randomly drop some outcome == 0 rows\n",
    "    if p_control < 1:\n",
    "        control_mask = (data[\"outcome\"] == 0)  # Identify control cases\n",
    "        sample_mask = control_mask & (np.random.rand(len(data)) > p_control)\n",
    "        data = data[~sample_mask]  # Drop some controls\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Load ITT trial data with sampling\n",
    "expanded_data_itt = load_expanded_data(expanded_data_itt, seed=1234, p_control=0.5)\n",
    "expanded_data_pp = load_expanded_data(expanded_data_pp, seed=1234, p_control=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_msm(data, weight_cols):\n",
    "    \"\"\" Fits a logistic regression model (MSM) using stabilized inverse probability weights. \"\"\"\n",
    "    \n",
    "    # Winsorization function to cap extreme weights at 99th percentile\n",
    "    def modify_weights(weights):\n",
    "        q99 = np.quantile(weights, 0.99)\n",
    "        return np.minimum(weights, q99)  # Cap weights at 99th percentile\n",
    "\n",
    "    # Get weights and apply winsorization\n",
    "    weights = modify_weights(data[weight_cols].sum(axis=1))  \n",
    "\n",
    "    # Define independent variables (formula-like structure)\n",
    "    data[\"followup_time_sq\"] = data[\"followup_time\"] ** 2\n",
    "    data[\"trial_period_sq\"] = data[\"trial_period\"] ** 2\n",
    "\n",
    "    independent_vars = [\"assigned_treatment\", \"x2\", \"followup_time\", \"followup_time_sq\", \"trial_period\", \"trial_period_sq\"]\n",
    "    X = sm.add_constant(data[independent_vars])  # Add intercept\n",
    "    y = data[\"outcome\"]  # Dependent variable\n",
    "\n",
    "    # Fit logistic regression (equivalent to glm with binomial logit in R)\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial(), freq_weights=weights).fit()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Fit MSM on ITT trial data\n",
    "msm_model_pp = fit_msm(expanded_data_pp, weight_cols=[\"weight\"])\n",
    "msm_model_itt = fit_msm(expanded_data_itt, weight_cols=[\"weight\"])\n",
    "\n",
    "# Print model summary (like R's `trial_itt@outcome_model`)\n",
    "print(msm_model_pp.summary())\n",
    "print(msm_model_itt.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance-covariance matrix\n",
    "vcov_matrix_itt = msm_model_itt.cov_params()\n",
    "# vcov_matrix_pp = msm_model_pp.cov_params()\n",
    "# print(vcov_matrix_pp)\n",
    "print(vcov_matrix_itt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "# Step 1: Fit a Kaplan-Meier Survival Model for ITT trial\n",
    "kmf_treated = KaplanMeierFitter()\n",
    "kmf_control = KaplanMeierFitter()\n",
    "\n",
    "# Subset data for assigned_treatment = 1 (treated) and 0 (control)\n",
    "data_treated = expanded_data_itt[expanded_data_itt[\"assigned_treatment\"] == 0]\n",
    "data_control = expanded_data_itt[expanded_data_itt[\"assigned_treatment\"] == 1]\n",
    "\n",
    "# Fit Kaplan-Meier survival curves\n",
    "kmf_treated.fit(data_treated[\"followup_time\"], event_observed=data_treated[\"outcome\"], label=\"Treated\")\n",
    "kmf_control.fit(data_control[\"followup_time\"], event_observed=data_control[\"outcome\"], label=\"Control\")\n",
    "\n",
    "# Step 2: Predict survival probabilities over time\n",
    "followup_times = np.arange(0, 11)  # Predict for 0 to 10 follow-up periods\n",
    "survival_treated = kmf_treated.survival_function_at_times(followup_times)\n",
    "survival_control = kmf_control.survival_function_at_times(followup_times)\n",
    "\n",
    "# Compute the survival difference\n",
    "survival_diff = survival_treated - survival_control\n",
    "# Step 3: Plot Survival Difference\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(followup_times, survival_diff, label=\"Survival Difference\", color=\"blue\")\n",
    "\n",
    "# Confidence intervals (assuming normal approximation)\n",
    "std_error = np.sqrt(survival_treated * (1 - survival_treated) / len(data_treated) +\n",
    "                    survival_control * (1 - survival_control) / len(data_control))\n",
    "\n",
    "ci_lower = survival_diff - 1.96 * std_error\n",
    "ci_upper = survival_diff + 1.96 * std_error\n",
    "\n",
    "# Add confidence interval lines\n",
    "plt.plot(followup_times, ci_lower, color=\"red\", linestyle=\"dashed\", label=\"2.5% CI\")\n",
    "plt.plot(followup_times, ci_upper, color=\"red\", linestyle=\"dashed\", label=\"97.5% CI\")\n",
    "\n",
    "# Labels and legend\n",
    "plt.xlabel(\"Follow-up Time\")\n",
    "plt.ylabel(\"Survival Difference\")\n",
    "plt.title(\"Survival Difference Over Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
