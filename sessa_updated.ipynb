{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7520c30c",
   "metadata": {},
   "source": [
    "# Wine Quality Clustering Analysis\n",
    "\n",
    "This notebook performs clustering analysis on red and white wine datasets. We use different clustering algorithms such as K-Means, DBSCAN, and Agglomerative Clustering to identify patterns in the data. Additionally, we apply preprocessing techniques like scaling and filtering to ensure robust analysis.\n",
    "\n",
    "## Steps in This Notebook:\n",
    "1. Load and preprocess the wine quality dataset\n",
    "2. Apply ECDF filtering to remove extreme values\n",
    "3. Perform feature scaling\n",
    "4. Use clustering algorithms (K-Means, DBSCAN, Agglomerative Clustering)\n",
    "5. Evaluate cluster quality using silhouette scores\n",
    "6. Visualize results using scatter plots and dendrograms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37546879",
   "metadata": {},
   "source": [
    "## Step 1: Load and Explore the Dataset\n",
    "\n",
    "We start by loading the red and white wine datasets and inspecting their structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811e6878",
   "metadata": {},
   "source": [
    "## Step 2: Preprocessing - ECDF Filtering\n",
    "\n",
    "To remove extreme values, we apply the Empirical Cumulative Distribution Function (ECDF). This ensures that only the middle 80% of the data (between the 10th and 90th percentile) is used for clustering analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240a977a",
   "metadata": {},
   "source": [
    "## Step 3: Feature Scaling\n",
    "\n",
    "Since different features have different scales, we apply standardization using `StandardScaler`. This transformation ensures that all features have a mean of 0 and a standard deviation of 1, making clustering more effective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16bc56f",
   "metadata": {},
   "source": [
    "## Step 4: Clustering Algorithms\n",
    "\n",
    "We apply three clustering methods:\n",
    "- **K-Means Clustering**: Partitions data into `k` clusters using the centroid method.\n",
    "- **DBSCAN (Density-Based Clustering)**: Identifies clusters based on density regions.\n",
    "- **Agglomerative Hierarchical Clustering**: Builds a hierarchy of clusters using the Ward linkage method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3749ce64",
   "metadata": {},
   "source": [
    "## Step 5: Evaluating Clustering Performance\n",
    "\n",
    "To assess how well the clustering algorithm performed, we compute the **Silhouette Score**. A higher score indicates better-defined clusters. DBSCAN results may have noise points (`-1` labels), so we exclude these when computing the silhouette score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcacf56",
   "metadata": {},
   "source": [
    "## Step 6: Visualization\n",
    "\n",
    "To better understand the clustering results, we use scatter plots and dendrograms:\n",
    "- **ECDF Plots**: Show the cumulative distribution of each feature.\n",
    "- **Scatter Plots**: Display clustering results for the first two features (e.g., `fixed acidity` vs. `volatile acidity`).\n",
    "- **Dendrograms**: Illustrate hierarchical clustering structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/sessa_assignment_updated.ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Save the modified notebook\u001b[39;00m\n\u001b[1;32m     58\u001b[0m updated_notebook_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/mnt/data/sessa_assignment_updated.ipynb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(updated_notebook_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     60\u001b[0m     nbformat\u001b[38;5;241m.\u001b[39mwrite(notebook, f)\n\u001b[1;32m     62\u001b[0m updated_notebook_path\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/sessa_assignment_updated.ipynb'"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "\n",
    "# Load the uploaded notebook file\n",
    "notebook_path = \"sessa_assignment.ipynb\"\n",
    "\n",
    "with open(notebook_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Add explanations and markdown cells\n",
    "markdown_cells = [\n",
    "    nbformat.v4.new_markdown_cell(\"# Wine Quality Clustering Analysis\\n\\n\"\n",
    "                                  \"This notebook performs clustering analysis on red and white wine datasets. \"\n",
    "                                  \"We use different clustering algorithms such as K-Means, DBSCAN, and Agglomerative Clustering \"\n",
    "                                  \"to identify patterns in the data. Additionally, we apply preprocessing techniques like scaling and filtering \"\n",
    "                                  \"to ensure robust analysis.\\n\\n\"\n",
    "                                  \"## Steps in This Notebook:\\n\"\n",
    "                                  \"1. Load and preprocess the wine quality dataset\\n\"\n",
    "                                  \"2. Apply ECDF filtering to remove extreme values\\n\"\n",
    "                                  \"3. Perform feature scaling\\n\"\n",
    "                                  \"4. Use clustering algorithms (K-Means, DBSCAN, Agglomerative Clustering)\\n\"\n",
    "                                  \"5. Evaluate cluster quality using silhouette scores\\n\"\n",
    "                                  \"6. Visualize results using scatter plots and dendrograms\"),\n",
    "\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 1: Load and Explore the Dataset\\n\\n\"\n",
    "                                  \"We start by loading the red and white wine datasets and inspecting their structure.\"),\n",
    "\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 2: Preprocessing - ECDF Filtering\\n\\n\"\n",
    "                                  \"To remove extreme values, we apply the Empirical Cumulative Distribution Function (ECDF). \"\n",
    "                                  \"This ensures that only the middle 80% of the data (between the 10th and 90th percentile) is used \"\n",
    "                                  \"for clustering analysis.\"),\n",
    "\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 3: Feature Scaling\\n\\n\"\n",
    "                                  \"Since different features have different scales, we apply standardization using `StandardScaler`. \"\n",
    "                                  \"This transformation ensures that all features have a mean of 0 and a standard deviation of 1, making clustering more effective.\"),\n",
    "\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 4: Clustering Algorithms\\n\\n\"\n",
    "                                  \"We apply three clustering methods:\\n\"\n",
    "                                  \"- **K-Means Clustering**: Partitions data into `k` clusters using the centroid method.\\n\"\n",
    "                                  \"- **DBSCAN (Density-Based Clustering)**: Identifies clusters based on density regions.\\n\"\n",
    "                                  \"- **Agglomerative Hierarchical Clustering**: Builds a hierarchy of clusters using the Ward linkage method.\"),\n",
    "\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 5: Evaluating Clustering Performance\\n\\n\"\n",
    "                                  \"To assess how well the clustering algorithm performed, we compute the **Silhouette Score**. \"\n",
    "                                  \"A higher score indicates better-defined clusters. DBSCAN results may have noise points (`-1` labels), \"\n",
    "                                  \"so we exclude these when computing the silhouette score.\"),\n",
    "\n",
    "    nbformat.v4.new_markdown_cell(\"## Step 6: Visualization\\n\\n\"\n",
    "                                  \"To better understand the clustering results, we use scatter plots and dendrograms:\\n\"\n",
    "                                  \"- **ECDF Plots**: Show the cumulative distribution of each feature.\\n\"\n",
    "                                  \"- **Scatter Plots**: Display clustering results for the first two features (e.g., `fixed acidity` vs. `volatile acidity`).\\n\"\n",
    "                                  \"- **Dendrograms**: Illustrate hierarchical clustering structures.\"),\n",
    "]\n",
    "\n",
    "# Insert markdown cells at the beginning of the notebook\n",
    "notebook[\"cells\"] = markdown_cells + notebook[\"cells\"]\n",
    "\n",
    "# Save the modified notebook\n",
    "updated_notebook_path = \"/mnt/data/sessa_assignment_updated.ipynb\"\n",
    "with open(updated_notebook_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    nbformat.write(notebook, f)\n",
    "\n",
    "updated_notebook_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
